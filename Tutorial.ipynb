# Step 1: Import libraries
import json
import random
import pickle

from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn import svm
from sklearn.naive_bayes import GaussianNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import f1_score

# Step 2: Define sentiment and review classes
class Sentiment:
    NEGATIVE = "NEGATIVE"
    NEUTRAL = "NEUTRAL"
    POSITIVE = "POSITIVE"

class Review:
    def __init__(self, text, score):
        self.text = text
        self.score = score
        self.sentiment = self.get_sentiment()

    def get_sentiment(self):
        if self.score <= 2:
            return Sentiment.NEGATIVE
        elif self.score == 3:
            return Sentiment.NEUTRAL
        else:
            return Sentiment.POSITIVE

class ReviewContainer:
    def __init__(self, reviews):
        self.reviews = reviews

    def get_text(self):
        return [x.text for x in self.reviews]

    def get_sentiment(self):
        return [x.sentiment for x in self.reviews]

    def evenly_distribute(self):
        positive = list(filter(lambda x: x.sentiment == Sentiment.POSITIVE, self.reviews))
        negative = list(filter(lambda x: x.sentiment == Sentiment.NEGATIVE, self.reviews))
        min_len = min(len(positive), len(negative))
        self.reviews = positive[:min_len] + negative[:min_len]
        random.shuffle(self.reviews)

# Step 3: Load and prepare dataset
reviews = []
with open('./data/books_small_10000.json') as f:
    for line in f:
        data = json.loads(line)
        reviews.append(Review(data['reviewText'], data['overall']))

print("Total Reviews:", len(reviews))

# Step 4: Split and balance dataset
train, test = train_test_split(reviews, test_size=0.33, random_state=42)

train_container = ReviewContainer(train)
test_container = ReviewContainer(test)

train_container.evenly_distribute()
test_container.evenly_distribute()

train_x = train_container.get_text()
train_y = train_container.get_sentiment()

test_x = test_container.get_text()
test_y = test_container.get_sentiment()

# Step 5: Vectorization
vectorizer = TfidfVectorizer()
train_x_vectors = vectorizer.fit_transform(train_x)
test_x_vectors = vectorizer.transform(test_x)

# Step 6: Train models
# SVM
clf_svm = svm.SVC(kernel='linear')
clf_svm.fit(train_x_vectors, train_y)

# Decision Tree
clf_dec = DecisionTreeClassifier()
clf_dec.fit(train_x_vectors, train_y)

# Naive Bayes (dense input)
clf_gnb = GaussianNB()
clf_gnb.fit(train_x_vectors.toarray(), train_y)

# Logistic Regression
clf_log = LogisticRegression(max_iter=1000)
clf_log.fit(train_x_vectors, train_y)

# Step 7: Evaluation
print("SVM Accuracy:", clf_svm.score(test_x_vectors, test_y))
print("Decision Tree Accuracy:", clf_dec.score(test_x_vectors, test_y))
print("Naive Bayes Accuracy:", clf_gnb.score(test_x_vectors.toarray(), test_y))
print("Logistic Regression Accuracy:", clf_log.score(test_x_vectors, test_y))

# F1 Score
f1 = f1_score(test_y, clf_svm.predict(test_x_vectors), average=None, labels=[Sentiment.POSITIVE, Sentiment.NEGATIVE])
print("SVM F1 Score:", f1)

# Step 8: Sample predictions
sample = ["Awesome product", "Worst thing ever", "Not good", "Absolutely loved it!"]
sample_vectors = vectorizer.transform(sample)
print("Sample Predictions:", clf_svm.predict(sample_vectors))

# Step 9: Hyperparameter tuning with Grid Search
parameters = {'kernel': ('linear', 'rbf'), 'C': [1, 4, 8, 16]}
svc = svm.SVC()
clf_grid = GridSearchCV(svc, parameters, cv=5)
clf_grid.fit(train_x_vectors, train_y)

print("Best Parameters:", clf_grid.best_params_)
print("Best Model Accuracy:", clf_grid.score(test_x_vectors, test_y))

# Step 10: Save model and vectorizer
with open('./models/sentiment_classifier.pkl', 'wb') as f:
    pickle.dump(clf_grid, f)

with open('./models/tfidf_vectorizer.pkl', 'wb') as f:
    pickle.dump(vectorizer, f)

# Step 11: Load model and predict
with open('./models/sentiment_classifier.pkl', 'rb') as f:
    loaded_model = pickle.load(f)

with open('./models/tfidf_vectorizer.pkl', 'rb') as f:
    loaded_vectorizer = pickle.load(f)

test_review = ["This is a fantastic book!"]
test_vec = loaded_vectorizer.transform(test_review)
print("Loaded Model Prediction:", loaded_model.predict(test_vec))
